{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis 2B\n",
    "## *Pandas Time Series Techniques*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T16:48:22.770179Z",
     "start_time": "2020-10-04T16:48:19.664954Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing the libraries for data processing\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "#matplotlib for visualizations\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preparation\n",
    "Merge the charts and the tracks datasets. Repeat the process from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T16:48:23.598705Z",
     "start_time": "2020-10-04T16:48:22.774177Z"
    }
   },
   "outputs": [],
   "source": [
    "# read and process the charts dataset\n",
    "charts_df = pd.read_csv('data/spotify_daily_charts.csv')\n",
    "#transform date column into a datetime column\n",
    "charts_df['date'] = pd.to_datetime(charts_df['date'])\n",
    "charts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T16:48:23.788597Z",
     "start_time": "2020-10-04T16:48:23.602703Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read and process the tracks dataset\n",
    "tracks_df = pd.read_csv('data/spotify_daily_charts_tracks.csv')\n",
    "tracks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T16:48:24.458214Z",
     "start_time": "2020-10-04T16:48:23.792595Z"
    }
   },
   "outputs": [],
   "source": [
    "df = charts_df.merge(tracks_df, on='track_id', how='left')\n",
    "\n",
    "df = df.drop(columns='track_name_y')\n",
    "df = df.rename(columns={'track_name_x':'track_name'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Seasonal and Trend decomposition using Loess (STL) Method\n",
    "\n",
    "From the [statsmodels documentation](https://otexts.com/fpp2/stl.html) :\n",
    "\n",
    "STL is a versatile and robust method for decomposing time series. \n",
    "\n",
    "STL is an acronym for “Seasonal and Trend decomposition using Loess”, while Loess is a method for estimating nonlinear relationships. \n",
    "\n",
    "The STL method was developed by Cleveland, Cleveland, McRae, & Terpenning (1990).\n",
    "\n",
    "STL has several advantages over the classical decomposition methods:\n",
    "\n",
    " - STL will handle any type of seasonality, not only monthly and quarterly data.\n",
    "\n",
    " - The seasonal component is allowed to change over time, and the rate of change can be controlled by the user.\n",
    "\n",
    " - The smoothness of the trend-cycle can also be controlled by the user.\n",
    "\n",
    "It can be robust to outliers (i.e., the user can specify a robust decomposition), so that occasional unusual observations will not affect the estimates of the trend-cycle and seasonal components. They will, however, affect the remainder component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T16:48:38.699081Z",
     "start_time": "2020-10-04T16:48:24.462212Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels import datasets\n",
    "\n",
    "\n",
    "sample_df = datasets.co2.load_pandas().data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T16:48:43.704221Z",
     "start_time": "2020-10-04T16:48:38.703078Z"
    }
   },
   "outputs": [],
   "source": [
    "res = sm.tsa.seasonal_decompose(sample_df['co2'].interpolate())\n",
    "resplot = res.plot()\n",
    "plt.suptitle(\"Mauna Loa Weekly Atmospheric CO2 Concentration\", y=1.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How does STL look like with top streamed artist Ben&Ben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T16:53:49.591325Z",
     "start_time": "2020-10-04T16:53:48.894723Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#get all dates\n",
    "data1 = pd.DataFrame({'date':pd.unique(df['date'])}).set_index('date')\n",
    "#get total streams of all charting songs of the artist per day\n",
    "artist_streams = df[df['artist']=='Ben&Ben'].groupby('date')[['streams']].sum()\n",
    "#merge with complete dates\n",
    "data1['streams']=artist_streams\n",
    "#fill days with no streams with 0\n",
    "data1['streams']=data1['streams'].fillna(0)\n",
    "data1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T16:53:53.521080Z",
     "start_time": "2020-10-04T16:53:49.595323Z"
    }
   },
   "outputs": [],
   "source": [
    "res = sm.tsa.seasonal_decompose(data1['streams'])\n",
    "resplot = res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T16:53:54.638442Z",
     "start_time": "2020-10-04T16:53:53.525079Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get each component \n",
    "data_decomposed = data1.copy()\n",
    "data_decomposed['trend_component'] = res.trend\n",
    "data_decomposed['seasonal_component'] = res.seasonal\n",
    "data_decomposed['residual_component'] = res.resid\n",
    "\n",
    "data_decomposed.tail(400).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How about for Jose Mari Chan, a Christmas song artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T16:53:55.501950Z",
     "start_time": "2020-10-04T16:53:54.644439Z"
    }
   },
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame({'date':pd.unique(df['date'])}).set_index('date')\n",
    "artist_streams = df[df['artist']=='Jose Mari Chan'].groupby('date')[['streams']].sum()\n",
    "data2['streams']=artist_streams\n",
    "data2['streams']=data2['streams'].fillna(0)\n",
    "data2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T16:53:58.642155Z",
     "start_time": "2020-10-04T16:53:57.730676Z"
    }
   },
   "outputs": [],
   "source": [
    "res = sm.tsa.seasonal_decompose(data2['streams'])\n",
    "data_decomposed = data2.copy()\n",
    "data_decomposed['trend_component'] = res.trend\n",
    "data_decomposed['seasonal_component'] = res.seasonal\n",
    "data_decomposed['residual_component'] = res.resid\n",
    "data_decomposed['season_strength'] = data_decomposed['seasonal_component']/data_decomposed['trend_component']\n",
    "data_decomposed[['streams','trend_component']].tail(400).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:01:58.554046Z",
     "start_time": "2020-10-04T17:01:57.374721Z"
    }
   },
   "outputs": [],
   "source": [
    "res1 = sm.tsa.seasonal_decompose(data1['streams'].diff()[1:])\n",
    "data_decomposed = data1[1:].copy()\n",
    "data_decomposed['trend_component'] = res1.trend\n",
    "data_decomposed['seasonal_component'] = res1.seasonal\n",
    "data_decomposed['residual_component'] = res1.resid\n",
    "data_decomposed['season_strength'] = data_decomposed['seasonal_component']/data_decomposed['trend_component']\n",
    "data_decomposed[['streams','seasonal_component','trend_component']].tail(400).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:02:53.194836Z",
     "start_time": "2020-10-04T17:02:52.232386Z"
    }
   },
   "outputs": [],
   "source": [
    "res2 = sm.tsa.seasonal_decompose(data2['streams'].diff()[1:])\n",
    "data_decomposed = data2[1:].copy()\n",
    "data_decomposed['trend_component'] = res2.trend\n",
    "data_decomposed['seasonal_component'] = res2.seasonal\n",
    "data_decomposed['residual_component'] = res2.resid\n",
    "data_decomposed['season_strength'] = data_decomposed['seasonal_component']/data_decomposed['trend_component']\n",
    "data_decomposed[['seasonal_component','trend_component']].tail(400).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Autocorrelation and Partial Autocorrelation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T16:48:51.521756Z",
     "start_time": "2020-10-04T16:48:51.509762Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity and differencing time series data\n",
    "\n",
    "A *stationary time series* is one whose statistical properties such as mean, variance, autocorrelation, etc. are all constant over time. Most statistical forecasting methods are based on the assumption that the time series can be rendered approximately stationary (i.e., “stationarized”) through the use of mathematical transformations. \n",
    "\n",
    "Lagged differencing is a simple transformation method that can be used to remove the seasonal component of the series. A lagged difference over an interval n is the difference of the value at current time t and another value at another past time t-n.\n",
    "\n",
    "This is easily done in pandas using the `diff()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:22:02.742552Z",
     "start_time": "2020-10-04T17:22:02.324791Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.plot(sample_df['co2'].interpolate().diff())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Autocorrelation Function (ACF)\n",
    "Simply put, a time series has autocorrelation if  autocorrelation is when a time series is linearly related to a lagged version of itself. \n",
    "\n",
    "It is a measure of how much of the past resembles the present.\n",
    "\n",
    "The ACF can be used to uncover and verify seasonality in time series data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:22:49.963578Z",
     "start_time": "2020-10-04T17:22:49.554812Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "acf = plot_acf(sample_df['co2'].interpolate().diff()[1:], lags=104, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values outside the band mean that the correlation value at that time lag is significant. \n",
    "\n",
    "The peaks occur at lag 25/52 and alternates in sign, which describes how CO2 falls globally as the seasons transition from summer to winter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Partial Autocorrelation Function (PACF)\n",
    "The partial autocorrelation function is a measure of the correlation between observations of a time series that are separated by k time units (yt and yt–k), AFTER adjusting for the presence of all the other terms of shorter lag (yt–1, yt–2, ..., yt–k–1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:23:54.517705Z",
     "start_time": "2020-10-04T17:23:52.962592Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "pacf = plot_pacf(sample_df['co2'].interpolate().diff()[1:], lags=104, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values outside the band mean that the correlation value at that time lag is significant. \n",
    "\n",
    "For CO2 concentration data, the PACF lags correlation are sharpest when the finishes approximately two annual (lag 100-104) cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q: How does ACF and PACF look like for Ben&Ben and Jose Mari Chan's total daily streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:55:03.179755Z",
     "start_time": "2020-10-04T17:55:02.667048Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.plot(data1['streams'].interpolate().diff()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:30:28.112912Z",
     "start_time": "2020-10-04T17:30:19.668736Z"
    }
   },
   "outputs": [],
   "source": [
    "#Ben & Ben\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax2 = fig.add_subplot(212)\n",
    "\n",
    "acf = plot_acf(data1['streams'].interpolate().diff()[1:], lags=365, ax=ax1)\n",
    "pacf = plot_pacf(data1['streams'].interpolate().diff()[1:], lags=365, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:55:54.978197Z",
     "start_time": "2020-10-04T17:55:54.458493Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.plot(data2['streams'].interpolate().diff()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:30:37.980276Z",
     "start_time": "2020-10-04T17:30:28.116910Z"
    }
   },
   "outputs": [],
   "source": [
    "#Jose Mari Chan\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax2 = fig.add_subplot(212)\n",
    "\n",
    "#full year lag\n",
    "acf = plot_acf(data2['streams'].interpolate().diff()[1:], lags=365, ax=ax1)\n",
    "pacf = plot_pacf(data2['streams'].interpolate().diff()[1:], lags=365, ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Day Deliverables*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (*Easy- Individual Work*) Among those included in the Spotify charts, pick an artist you like. \n",
    "\n",
    "   a. Plot the streams and positions of their top 5 streamed songs.\n",
    "\n",
    "   b. Compare these charts with streams and positions of what you feel to be a possible collaborator/competitor/related artist. \n",
    "\n",
    "   What insights can you draw from the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (*Intermediate - Group Work*) A song may be classified as follows:\n",
    "\n",
    "   - **Mainstay** - Song with high streams ($>X_1$ streams) and position ($>P_1$ position) all throughout the year\n",
    "   - **Viral** - Song that reach the peak position fast with high increase in streams ($>X_2$ streams/day),\n",
    "     followed by a rapid decline in position ($P_2$ places/day) and streams ($>X_3$ streams/day)\n",
    "   - **Seasonal** - Song that consistently appear ($>C$ autocorrelation score) OR stay and garner considerable streams ($>X_4$ streams) within a certain season and go into low ranks/ disappear from the chart after the season\n",
    "    \n",
    "   a. Discuss among your group how you would define and set values to the thresholds that you will use to classify the songs according to the categories as described above. (You may add more thresholds to refine the definitions, as you see fit)\n",
    "   \n",
    "   b. Name as many songs as you can per category and plot their streams and position as a time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (*Advanced - Group Work, Optional*) What percentage of Spotify charts streams from 2018-2020 are from mainstay songs? viral songs? seasonal songs? songs that do not belong in any of these categories? What does this reveal about the streaming market?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
